{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerometer Log Visualizer\n",
    "I programmed an Arduino to collect accelerometer data and dump into an SD card as a CSV.  The file format is\n",
    "\n",
    "(sec since on), (x_last_reading), (y_last_reading), (z_last_reading), (x_reading), (y_reading), (z_reading)\n",
    "\n",
    "The data only gets logged if last reading is past a certain threshold from first reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some random data to test log visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    import csv\n",
    "    import random\n",
    "    tsec = 0;\n",
    "    with open('tmp.csv', 'w') as csvfile:\n",
    "        for x in range(0,100):\n",
    "            tsec = random.randint(tsec, tsec+3600)\n",
    "            if tsec >= 60*60*8:\n",
    "                break;\n",
    "            spamwriter = csv.writer(csvfile)\n",
    "            spamwriter.writerow([tsec,\n",
    "                                 random.randint(50,110),\n",
    "                                 random.randint(50,110),\n",
    "                                 random.randint(50,110),\n",
    "                                 random.randint(50,110),\n",
    "                                 random.randint(50,110),\n",
    "                                 random.randint(50,110)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the log data\n",
    "Read in CSV and store as magnitude of tuple-2 of (hour in float, magnitude of change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def read_sleep_data(fn):\n",
    "    '''Return an array of tuple [(hr_offset, magnitude of movement), (hr_offset, mag)...]'''\n",
    "    data_log = []\n",
    "    start_hr = 0 #21.15 # 9:15pm\n",
    "    ignore_first_hours = 0 #1.5\n",
    "    with open(fn, 'r') as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for row in spamreader:\n",
    "            sec = long(row[0])\n",
    "            last = np.array(map(float, row[1:4]))\n",
    "            cur = np.array(map(float, row[4:]))\n",
    "            hr = float(sec)/3600.0 \n",
    "            diff_vec = last-cur\n",
    "            mag = np.linalg.norm(diff_vec)        \n",
    "            data_log.append((hr,mag))\n",
    "        data_log = np.array(data_log)\n",
    "    \n",
    "    # Is the first entry larger than 2nd?  If so, we have our start time\n",
    "    # in the first entry\n",
    "    # IE 85500,0.1,0,0\n",
    "    if data_log[0][0] > data_log[1][0]:\n",
    "        # When did log first start in real time - ie 22.5 == 10:30pm\n",
    "        start_hr = data_log[0][0]\n",
    "        ignore_first_hours = data_log[0][1]\n",
    "        data_log = data_log[1:]\n",
    "    \n",
    "    # If second entry is negative than we have the subjective quality encoded \n",
    "    # in the magnitude\n",
    "    if data_log[0][0] < 0:\n",
    "        quality = data_log[0][1]\n",
    "        data_log = data_log[1:]\n",
    "        \n",
    "    return [start_hr, data_log]\n",
    "\n",
    "fn = \"/Users/jpien/Desktop/datalog_2015_05_20__22_00__23_30.csv\"\n",
    "fn = \"/Users/jpien/Desktop/datalog.csv\"\n",
    "\n",
    "[start_hr, data_log] = read_sleep_data(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the magnitudes of readings within the same time quanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sleep_data(data_log):\n",
    "    '''Returns cleaned data_log'''\n",
    "    # Find last second\n",
    "    [nr, nc] = np.shape(data_log)\n",
    "\n",
    "    #print data_log\n",
    "    accum_row = [data_log[0,0], data_log[0,1]]\n",
    "    new_data_log = [np.copy(accum_row)] # We want first sample\n",
    "    for row in data_log:\n",
    "        cur_hr = row[0]\n",
    "        movement = row[1]\n",
    "    \n",
    "        # Time from last time is less than 1.5 seconds away\n",
    "        if np.abs(cur_hr - accum_row[0]) < 0.003:\n",
    "            # Sum the movement\n",
    "            accum_row[1] += movement\n",
    "        else:\n",
    "            # New entry\n",
    "            new_data_log.append(accum_row)\n",
    "        \n",
    "            # Start new entry    \n",
    "            accum_row = [cur_hr, movement]\n",
    "        \n",
    "    return np.array(new_data_log)\n",
    "\n",
    "cleaned_data_log = clean_sleep_data(data_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute some data from readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_readable_time(float_hour):\n",
    "    am_pm = \"am\"\n",
    "    rt_hour = float_hour\n",
    "    \n",
    "    if ((int(float_hour / 12)) % 2) == 0:\n",
    "        am_pm = \"am\"\n",
    "    else:\n",
    "        am_pm = \"pm\"\n",
    "    rt_hour = int(float_hour % 12)\n",
    "        \n",
    "    the_minute = int((float_hour - int(float_hour)) * 60)\n",
    "    return str(rt_hour) + \":\" + str(the_minute) + am_pm\n",
    "\n",
    "def analyze_sleep_data_log(data_log):\n",
    "    # When did we go to sleep - figure out first chunk of quiescent 20 minutes\n",
    "    last_data = data_log[0]\n",
    "    sleep_start_hr_offset = 0;\n",
    "    for i in range(len(data_log)):\n",
    "        ddd = data_log[i]\n",
    "        if ddd[0] - last_data[0] > 0.33:\n",
    "            sleep_start_hr_offset = last_data[0]\n",
    "            break;\n",
    "        last_data = ddd\n",
    "        \n",
    "    # When did we get up?\n",
    "    sleep_stop_hr_offset = data_log[-1,0]\n",
    "    \n",
    "    # Let's clean up data further by removing small movements\n",
    "    move_thresh = 10\n",
    "    new_data_log = []\n",
    "    for ddd in data_log:\n",
    "        if ddd[1] > move_thresh:\n",
    "            new_data_log.append(ddd)\n",
    "    new_data_log = np.array(new_data_log)\n",
    "    \n",
    "    # Between sleep time and get up time, get all the tuples of quiescent chunks\n",
    "    # Quiescent == minimal movement for 30 min or 0.5 hours\n",
    "    quiet_intervals = [] # [[(hr,mv),(hr.mv)], [(hr,mv),(hr,mv)], ...]\n",
    "    last_data = new_data_log[0]\n",
    "    for i in range(len(new_data_log)):\n",
    "        ddd = new_data_log[i]\n",
    "        \n",
    "        # Before we went to sleep or after we got up\n",
    "        if ddd[0] < sleep_start_hr_offset:\n",
    "            last_data = ddd\n",
    "            continue\n",
    "            \n",
    "        if ddd[0] >= sleep_stop_hr_offset:\n",
    "            break\n",
    "            \n",
    "        if ddd[0] - last_data[0] >= 1.0:\n",
    "            quiet_intervals.append([last_data,ddd])\n",
    "            \n",
    "        last_data = ddd\n",
    "        \n",
    "    quiet_intervals = np.array(quiet_intervals)\n",
    "    \n",
    "    # Average quiet interval\n",
    "    quiet_hr_array = []\n",
    "    for itv in quiet_intervals:\n",
    "        quiet_hrs = itv[1][0] - itv[0][0]\n",
    "        quiet_hr_array.append(quiet_hrs)\n",
    "    quiet_hr_array = np.array(quiet_hr_array)\n",
    "    quiet_hr_intervals = np.shape(quiet_hr_array)[0]\n",
    "    quiet_hours_mean = quiet_hr_array.mean()\n",
    "    quiet_hours_std = quiet_hr_array.std()\n",
    "    #print (quiet_intervals + start_hr) %24\n",
    "    \n",
    "\n",
    "    return [sleep_start_hr_offset, sleep_stop_hr_offset, quiet_hours_mean, quiet_hours_std, quiet_hr_intervals]\n",
    "\n",
    "[ sleep_start, sleep_stop, quiet_hrs_mean, quiet_hrs_std, quiet_hr_intervals ] = analyze_sleep_data_log(cleaned_data_log)\n",
    "\n",
    "log_start_time = convert_to_readable_time(start_hr)\n",
    "got_up_time = convert_to_readable_time(start_hr + sleep_stop)\n",
    "slept_time = convert_to_readable_time(start_hr + sleep_start)\n",
    "\n",
    "print \"We started logging at: \" + log_start_time\n",
    "print \"We went to sleep at: \" + slept_time\n",
    "print \"We slept for (hours): \" + str(sleep_stop - sleep_start)\n",
    "print \"We got up at: \" + got_up_time\n",
    "print \"Sleeps cycles with more than 60 min of sleep: \" + str(quiet_hr_intervals)\n",
    "print \"Length of sleep cycle fell btw(hours): \" + \\\n",
    "    \"{0:.2f}\".format(quiet_hrs_mean-quiet_hrs_std) + \" to \" + \"{0:.2f}\".format(quiet_hrs_mean+quiet_hrs_std)\n",
    "    #(\"%.2d\" % quiet_hrs_mean-quiet_hrs_std) + \" to \" + (\"%.2d\" %quiet_hrs_mean+quiet_hrs_std)\n",
    "#print \"Standard deviation of sleep cycle (hours): \" + str(quiet_hrs_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore data from before we went to sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def purge_awake_data(data_log):\n",
    "    '''Get rid of data from when we determined to be awake'''\n",
    "    new_data_log = [[0,0]]\n",
    "    for ddd in data_log:\n",
    "        if ddd[0] >= sleep_start and \\\n",
    "            ddd[0] < sleep_stop:\n",
    "            new_data_log.append(ddd)\n",
    "    return np.array(new_data_log)\n",
    "\n",
    "plot_data_log = purge_awake_data(cleaned_data_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data plots to see when we made movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.plot(data_log[:,0],data_log[:,1])\n",
    "#plt.show()\n",
    "max_hr = np.max(plot_data_log[:,0]) + 1\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(14, 8)\n",
    "plt.xticks(np.arange(0,max_hr), np.arange(start_hr,start_hr+max_hr)%24)\n",
    "plt.bar(plot_data_log[5:,0],plot_data_log[5:,1], width=0.01)\n",
    "plt.xlabel(\"Hour\", fontsize = 20)\n",
    "plt.ylabel(\"Magnitude of movement\", fontsize = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
